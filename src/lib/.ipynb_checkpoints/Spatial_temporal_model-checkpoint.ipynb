{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import pickle, glob \n",
    "import time , math\n",
    "\n",
    "import gpxpy.geo\n",
    "import random \n",
    "from operator import is_not\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost:27017')\n",
    "db_air_quality = client.air_quality_model_hkust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': {'$gte': 1380088870.9441829}}\n"
     ]
    }
   ],
   "source": [
    "month = 60*60*24*60\n",
    "months = 25\n",
    "ts = time.time() - months * month\n",
    "query = {\"time\": {\"$gte\": ts}}\n",
    "print(query)\n",
    "\n",
    "time_diff = 2*30*70 # 70 minutes 60 +10 buffer \n",
    "distance_diff = 15000 # 10 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131400 time 25 months stations:  ['KT_A' 'YL_A' 'TC_A' 'TM_A' 'TW_A' 'KC_A' 'EN_A' 'MB_A' 'CL_R' 'CB_R'\n",
      " 'TP_A' 'ST_A' 'SP_A' 'MKaR' 'CW_A'] 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQHI</th>\n",
       "      <th>AQI</th>\n",
       "      <th>CO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>SO2</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>station_code</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.07</td>\n",
       "      <td>100.50</td>\n",
       "      <td>None</td>\n",
       "      <td>43.09</td>\n",
       "      <td>136.17</td>\n",
       "      <td>3.57</td>\n",
       "      <td>33.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.67</td>\n",
       "      <td>22.3147</td>\n",
       "      <td>114.2233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KT_A</td>\n",
       "      <td>28.293010</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.73</td>\n",
       "      <td>26.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.17</td>\n",
       "      <td>26.60</td>\n",
       "      <td>10.71</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.05</td>\n",
       "      <td>22.4467</td>\n",
       "      <td>114.0203</td>\n",
       "      <td>80.142857</td>\n",
       "      <td>YL_A</td>\n",
       "      <td>29.007143</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.84</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.64</td>\n",
       "      <td>18.62</td>\n",
       "      <td>13.27</td>\n",
       "      <td>17.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>22.2903</td>\n",
       "      <td>113.9411</td>\n",
       "      <td>78.785714</td>\n",
       "      <td>TC_A</td>\n",
       "      <td>29.221429</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.95</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>14.89</td>\n",
       "      <td>28.19</td>\n",
       "      <td>9.18</td>\n",
       "      <td>25.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>22.3908</td>\n",
       "      <td>113.9767</td>\n",
       "      <td>82.285714</td>\n",
       "      <td>TM_A</td>\n",
       "      <td>29.071429</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.26</td>\n",
       "      <td>66.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>28.19</td>\n",
       "      <td>68.62</td>\n",
       "      <td>4.59</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.96</td>\n",
       "      <td>22.3733</td>\n",
       "      <td>114.1121</td>\n",
       "      <td>99.857143</td>\n",
       "      <td>TW_A</td>\n",
       "      <td>26.376190</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>184.619048</td>\n",
       "      <td>5.760848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AQHI     AQI    CO    NO2     NOX     O3   PM10  PM2_5   SO2  latitude  \\\n",
       "0   5.07  100.50  None  43.09  136.17   3.57  33.00  20.00  2.67   22.3147   \n",
       "14  2.73   26.25  0.45  11.17   26.60  10.71  21.00   0.00  3.05   22.4467   \n",
       "13  2.84   25.00  0.39  10.64   18.62  13.27  17.00   5.00  3.44   22.2903   \n",
       "12  2.95   35.00  0.41  14.89   28.19   9.18  25.00   9.00  1.53   22.3908   \n",
       "11  3.26   66.25  0.70  28.19   68.62   4.59   8.00   7.00  4.96   22.3733   \n",
       "\n",
       "    longitude  relative_humidity station_code  temperature       time  \\\n",
       "0    114.2233                NaN         KT_A    28.293010 2016-06-01   \n",
       "14   114.0203          80.142857         YL_A    29.007143 2016-06-01   \n",
       "13   113.9411          78.785714         TC_A    29.221429 2016-06-01   \n",
       "12   113.9767          82.285714         TM_A    29.071429 2016-06-01   \n",
       "11   114.1121          99.857143         TW_A    26.376190 2016-06-01   \n",
       "\n",
       "    wind_direction  wind_speed  \n",
       "0              NaN         NaN  \n",
       "14             NaN         NaN  \n",
       "13             NaN         NaN  \n",
       "12             NaN         NaN  \n",
       "11      184.619048    5.760848  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_q = db_air_quality.aqi_aggregation_hkust_5000_1800_subhour.find(query)\n",
    "data_lis = []\n",
    "for d in data_q:\n",
    "    data_ ={}\n",
    "    for k, v in d.items():\n",
    "        if type(v) == type(dict()):\n",
    "            for k1, v1 in v.items():\n",
    "                try:\n",
    "                    data_[k1] = v1['obs']\n",
    "                except:\n",
    "                    data_[k1] = v1\n",
    "        else:\n",
    "            try:\n",
    "                data_[k] = v['obs']\n",
    "            except:\n",
    "                data_[k] = v\n",
    "            \n",
    "            \n",
    "    data_lis.append(data_)\n",
    "    \n",
    "df_air_quality = pd.DataFrame(data_lis)\n",
    "df_air_quality = df_air_quality.drop('_id',1)\n",
    "df_air_quality = df_air_quality.drop('station_name',1)\n",
    "df_air_quality = df_air_quality.drop('station_type',1)\n",
    "df_air_quality['time'] = df_air_quality.time.apply(lambda x : datetime.fromtimestamp(x))\n",
    "df_air_quality = df_air_quality.sort_values('time', ascending=True)\n",
    "\n",
    "\n",
    "df_air_quality.to_csv(\"df_air_quality.csv\")\n",
    "print(len(df_air_quality) , \"time\", months , \"months\", \"stations: \", df_air_quality.station_code.unique(), len(df_air_quality.station_code.unique()))\n",
    "df_air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All stations  ['KT_A', 'YL_A', 'TC_A', 'TM_A', 'TW_A', 'KC_A', 'EN_A', 'MB_A', 'CL_R', 'CB_R', 'TP_A', 'ST_A', 'SP_A', 'MKaR', 'CW_A']\n"
     ]
    }
   ],
   "source": [
    "print(\"All stations \" , list(df_air_quality.station_code.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def compute_distance(row, station, lat1, lon1):\n",
    "    \n",
    "    if station == row['station_code']:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    lat2 = float(row['latitude'])\n",
    "    lon2 = float(row['longitude'])\n",
    "    \n",
    "    distance = gpxpy.geo.haversine_distance(lat1, lon1, lat2, lon2)/ 1000\n",
    "    \n",
    "    if distance < 10:\n",
    "        return 10.0\n",
    "    elif distance < 30: \n",
    "        return 30.0\n",
    "    elif distance < 100:\n",
    "        return 100.0\n",
    "    return 1000\n",
    "\n",
    "\n",
    "def degrees_to_cardinal(d):\n",
    "    '''\n",
    "    note: this is highly approximate...\n",
    "    '''\n",
    "    dirs = [\"N\", \"NNE\", \"NE\", \"ENE\", \"E\", \"ESE\", \"SE\", \"SSE\",\n",
    "            \"S\", \"SSW\", \"SW\", \"WSW\", \"W\", \"WNW\", \"NW\", \"NNW\"]\n",
    "    ix = int((d + 11.25)/22.5)\n",
    "    return dirs[ix % 16]\n",
    "\n",
    "def get_angle_from_quadrant(row, lat1, lon1, station):\n",
    "    \n",
    "    if station == row['station_code']:\n",
    "        return \"self\"\n",
    "    \n",
    "    lat2 = float(row['latitude'])\n",
    "    lon2 = float(row['longitude'])\n",
    "    \n",
    "    pointA = (lat1, lon1)\n",
    "    pointB = (lat2, lon2)\n",
    "    \n",
    "    lat1 = math.radians(pointA[0])\n",
    "    lat2 = math.radians(pointB[0])\n",
    "\n",
    "    diffLong = math.radians(pointB[1] - pointA[1])\n",
    "\n",
    "    x = math.sin(diffLong) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1) * math.cos(lat2) * math.cos(diffLong))\n",
    "\n",
    "    initial_bearing = math.atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = math.degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "\n",
    "    return degrees_to_cardinal(compass_bearing)\n",
    "\n",
    "\n",
    "def nearest_30(mino):\n",
    "    if mino > 30:\n",
    "        return \"30\"\n",
    "    else:\n",
    "        return \"00\"\n",
    "    \n",
    "def datetime_to_float(d):\n",
    "    epoch = datetime.utcfromtimestamp(0)\n",
    "    total_seconds =  (d - epoch).total_seconds()\n",
    "    # total_seconds will be in decimals (millisecond precision)\n",
    "    return int(total_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stations  15\n",
      "KT_A 105120\n",
      "YL_A 61320\n",
      "TC_A 52560\n",
      "TM_A 70080\n",
      "TW_A 96360\n",
      "KC_A 113880\n",
      "EN_A 78840\n",
      "MB_A 61320\n",
      "CL_R 122640\n",
      "CB_R 96360\n",
      "TP_A 78840\n",
      "ST_A 113880\n",
      "SP_A 113880\n",
      "MKaR 105120\n",
      "CW_A 105120\n"
     ]
    }
   ],
   "source": [
    "stations_ = df_air_quality.station_code.unique()\n",
    "print(\"Total stations \", len(stations_))\n",
    "\n",
    "data_dict_by_station = {}\n",
    "\n",
    "for station in stations_: \n",
    "    outfilename = 'data/weather_data_'+station+\".csv\"\n",
    "    lat = list(df_air_quality[df_air_quality.station_code == station].latitude.unique()).pop()\n",
    "    lon = list(df_air_quality[df_air_quality.station_code == station].longitude.unique()).pop()\n",
    "    df = df_air_quality.copy()\n",
    "    df['distance'] = df.apply(lambda row : compute_distance(row, station, lat, lon ), axis=1)\n",
    "    \n",
    "    df = df[df.distance < 400]\n",
    "    \n",
    "    df['angle_from_station'] = df.apply(lambda row : get_angle_from_quadrant(row, lat, lon,  station ), axis=1)\n",
    "    df['date'] = df.time.apply(lambda x : x.date())\n",
    "    df['hour'] = df.time.apply(lambda x : x.hour)\n",
    "    df['minutes'] = df.time.apply(lambda x : nearest_30(x.minute))\n",
    "    df['base_station'] = station\n",
    "    \n",
    "    df = df.drop('latitude', axis=1)\n",
    "    df = df.drop('longitude', axis=1)    \n",
    "    df = df.drop('station_code', axis=1)\n",
    "    \n",
    "    \n",
    "    AQs = [\"AQHI\", \"AQI\", \"CO\", \"NO2\", \"NOX\", \"O3\", \"PM10\", \"PM2_5\", \"SO2\"]\n",
    "    for AQ in AQs:\n",
    "        df[AQ] = pd.to_numeric(df[AQ], errors='coerce')\n",
    "    df = df.fillna(0.0)\n",
    "    df = df.groupby(['base_station', 'date', 'hour', 'angle_from_station', 'distance', 'minutes']).mean().reset_index()\n",
    "    df['time'] = df.apply(lambda row : str(row['date']) + \" \" + str(row['hour']) +\":\"+ str(row['minutes']) +\":00\", axis=1)\n",
    "    df['time'] = df.time.apply(lambda row : datetime_to_float(datetime.strptime(row, '%Y-%m-%d %H:%M:%S')))\n",
    "    df = df.drop('date', axis=1)\n",
    "    df = df.drop('hour', axis=1)    \n",
    "    df = df.drop('minutes', axis=1)\n",
    "    \n",
    "    df.to_csv(outfilename)\n",
    "    \n",
    "    data_dict_by_station['station'] = outfilename\n",
    "    print(station , len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_station</th>\n",
       "      <th>angle_from_station</th>\n",
       "      <th>distance</th>\n",
       "      <th>AQHI</th>\n",
       "      <th>AQI</th>\n",
       "      <th>CO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>SO2</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>E</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.265</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>25.535</td>\n",
       "      <td>60.375</td>\n",
       "      <td>14.285</td>\n",
       "      <td>19.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.675</td>\n",
       "      <td>41.904762</td>\n",
       "      <td>28.853316</td>\n",
       "      <td>122.357143</td>\n",
       "      <td>2.282143</td>\n",
       "      <td>1464739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>ENE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.070</td>\n",
       "      <td>100.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.090</td>\n",
       "      <td>136.170</td>\n",
       "      <td>3.570</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.293010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>ESE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.950</td>\n",
       "      <td>72.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>30.850</td>\n",
       "      <td>98.400</td>\n",
       "      <td>6.630</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.440</td>\n",
       "      <td>83.809524</td>\n",
       "      <td>28.442857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>N</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.670</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.300</td>\n",
       "      <td>29.260</td>\n",
       "      <td>10.710</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.150</td>\n",
       "      <td>80.285714</td>\n",
       "      <td>28.971429</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>2.277780</td>\n",
       "      <td>1464739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>NE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.750</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.790</td>\n",
       "      <td>7.450</td>\n",
       "      <td>18.370</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.728571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464739200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  base_station angle_from_station  distance   AQHI     AQI    CO     NO2  \\\n",
       "0         CW_A                  E      10.0  4.265   60.00  0.22  25.535   \n",
       "1         CW_A                ENE      10.0  5.070  100.50  0.00  43.090   \n",
       "2         CW_A                ESE      10.0  3.950   72.50  0.54  30.850   \n",
       "3         CW_A                  N      30.0  2.670   31.25  0.00  13.300   \n",
       "4         CW_A                 NE     100.0  2.750   18.00  0.62   4.790   \n",
       "\n",
       "       NOX      O3  PM10  PM2_5    SO2  relative_humidity  temperature  \\\n",
       "0   60.375  14.285  19.5   13.0  2.675          41.904762    28.853316   \n",
       "1  136.170   3.570  33.0   20.0  2.670           0.000000    28.293010   \n",
       "2   98.400   6.630  19.0    9.0  3.440          83.809524    28.442857   \n",
       "3   29.260  10.710  15.0    9.0  1.150          80.285714    28.971429   \n",
       "4    7.450  18.370  14.0    8.0  2.670           0.000000    25.728571   \n",
       "\n",
       "   wind_direction  wind_speed        time  \n",
       "0      122.357143    2.282143  1464739200  \n",
       "1        0.000000    0.000000  1464739200  \n",
       "2        0.000000    0.000000  1464739200  \n",
       "3      261.000000    2.277780  1464739200  \n",
       "4        0.000000    0.000000  1464739200  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KT_A 8760\n",
      "YL_A 8760\n",
      "TC_A 8760\n",
      "TM_A 8760\n",
      "TW_A 8760\n",
      "KC_A 8760\n",
      "EN_A 8760\n",
      "MB_A 8760\n",
      "CL_R 8760\n",
      "CB_R 8760\n",
      "TP_A 8760\n",
      "ST_A 8760\n",
      "SP_A 8760\n",
      "MKaR 8760\n",
      "CW_A 8760\n"
     ]
    }
   ],
   "source": [
    "for station in stations_: \n",
    "    outfilename = 'weather_data_'+station+\".csv\"\n",
    "    df = pd.DataFrame.from_csv(\"data/\"+outfilename)\n",
    "    \n",
    "    df['group_id'] = df.apply(lambda row : str(int(row['distance'])) +\"_\"+ str(row['angle_from_station']), axis=1)\n",
    "    df = df.drop('angle_from_station', axis=1)\n",
    "    df = df.drop('distance', axis=1)\n",
    "    df = df.groupby(['base_station', 'time','group_id']).mean()\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    grouped = df.groupby(['base_station', 'time'])\n",
    "    \n",
    "    lis_ = []\n",
    "    \n",
    "    ct = 0 \n",
    "    for name, group in grouped:\n",
    "        dicti = {\n",
    "            'base_station' : name[0],\n",
    "            'time' : name[1]\n",
    "        }\n",
    "        \n",
    "        for index, row in group.iterrows():\n",
    "            ct +=1\n",
    "            name = row['group_id']\n",
    "            row = row.to_dict()\n",
    "            for key in row:\n",
    "                if key not in ['time', 'base_station', 'group_id', 'latitude', 'longitude']:\n",
    "                    dicti[name + \"_\" + key] = row[key]\n",
    "\n",
    "        lis_.append(dicti)\n",
    "\n",
    "    df = pd.DataFrame(lis_).set_index(['base_station', 'time'])\n",
    "    \n",
    "    cols = ['relative_humidity', 'temperature', 'wind_direction', 'wind_speed' ,'NO2', 'NOX', 'O3', 'CO', 'SO2', 'AQHI','AQI', 'PM10', 'PM2_5']\n",
    "    for col in cols:\n",
    "        name = \"0_self_\" + col\n",
    "        df[col] = df[name]\n",
    "        df = df.drop(name, axis=1)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "\n",
    "    df.to_csv(\"data/grouped_\" + outfilename)\n",
    "    \n",
    "    data_dict_by_station['station'] = outfilename\n",
    "    \n",
    "    print(station , len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_station</th>\n",
       "      <th>time</th>\n",
       "      <th>100_NE_AQHI</th>\n",
       "      <th>100_NE_AQI</th>\n",
       "      <th>100_NE_CO</th>\n",
       "      <th>100_NE_NO2</th>\n",
       "      <th>100_NE_NOX</th>\n",
       "      <th>100_NE_O3</th>\n",
       "      <th>100_NE_PM10</th>\n",
       "      <th>100_NE_PM2_5</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>O3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>AQHI</th>\n",
       "      <th>AQI</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>1464739200</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.79</td>\n",
       "      <td>7.45</td>\n",
       "      <td>18.37</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.888000</td>\n",
       "      <td>7.45</td>\n",
       "      <td>12.23</td>\n",
       "      <td>13.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.50</td>\n",
       "      <td>17.50</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>1464742800</td>\n",
       "      <td>2.88</td>\n",
       "      <td>17.87</td>\n",
       "      <td>0.63</td>\n",
       "      <td>7.98</td>\n",
       "      <td>13.30</td>\n",
       "      <td>17.86</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.132143</td>\n",
       "      <td>6.38</td>\n",
       "      <td>12.23</td>\n",
       "      <td>16.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.60</td>\n",
       "      <td>16.25</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>1464746400</td>\n",
       "      <td>3.06</td>\n",
       "      <td>19.83</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.79</td>\n",
       "      <td>7.45</td>\n",
       "      <td>24.49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.65</td>\n",
       "      <td>17.67</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>1464750000</td>\n",
       "      <td>3.53</td>\n",
       "      <td>22.87</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3.19</td>\n",
       "      <td>5.32</td>\n",
       "      <td>32.65</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.77</td>\n",
       "      <td>18.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CW_A</td>\n",
       "      <td>1464753600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.79</td>\n",
       "      <td>31.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  base_station        time  100_NE_AQHI  100_NE_AQI  100_NE_CO  100_NE_NO2  \\\n",
       "0         CW_A  1464739200         2.75       18.00       0.62        4.79   \n",
       "1         CW_A  1464742800         2.88       17.87       0.63        7.98   \n",
       "2         CW_A  1464746400         3.06       19.83       0.62        4.79   \n",
       "3         CW_A  1464750000         3.53       22.87       0.62        3.19   \n",
       "4         CW_A  1464753600         3.89       24.40       0.62        3.19   \n",
       "\n",
       "   100_NE_NOX  100_NE_O3  100_NE_PM10  100_NE_PM2_5  ...    wind_speed   NO2  \\\n",
       "0        7.45      18.37         14.0           8.0  ...      3.888000  7.45   \n",
       "1       13.30      17.86         15.0           8.0  ...      4.132143  6.38   \n",
       "2        7.45      24.49         15.0           9.0  ...      0.000000  0.00   \n",
       "3        5.32      32.65         17.0          12.0  ...      0.000000  0.00   \n",
       "4        4.79      31.12         19.0          13.0  ...      0.000000  0.00   \n",
       "\n",
       "     NOX     O3   CO   SO2  AQHI    AQI  PM10  PM2_5  \n",
       "0  12.23  13.78  0.0  1.53  2.50  17.50  15.0    8.0  \n",
       "1  12.23  16.33  0.0  1.15  2.60  16.25  17.0    9.0  \n",
       "2   0.00   0.00  0.0  0.00  2.65  17.67  21.0   11.0  \n",
       "3   0.00   0.00  0.0  0.00  2.77  18.00  19.0    9.0  \n",
       "4   0.00   0.00  0.0  0.00  0.00  18.00  18.0    9.0  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_percentile(df , test_size=0.25, col = 'time'):\n",
    "    df = df.copy()\n",
    "    p_x = float(np.percentile(sorted(df[col]), test_size * 100))\n",
    "    filter_pos = df[col] < p_x\n",
    "    filter_neg = df[col] >= p_x\n",
    "    return df[filter_pos].copy(), df[filter_neg].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_regression_train_test_for_spatial_patterns(station_name, test_size=0.25):\n",
    "    \n",
    "    infilename = 'data/grouped_weather_data_'+station_name+\".csv\"\n",
    "    df = pd.DataFrame.from_csv(infilename)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = df[col].apply(lambda x: float(x)).copy()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    train_y_pollution = ['NO2', 'NOX', 'O3', 'CO', 'SO2', 'AQHI','AQI', 'PM10', 'PM2_5']\n",
    "    train_columns = []\n",
    "    for col in df.columns:\n",
    "        if col not in train_y_pollution:\n",
    "            train_columns.append(col)\n",
    "\n",
    "    list_ = list(set(df.base_station))\n",
    "        \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list_)\n",
    "\n",
    "    df['base_station'] = df.base_station.apply(lambda x : le.transform([x])[0])\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size = test_size)\n",
    "    \n",
    "#     test_df = test_df[test_df.angle_from_station == le.transform(['self'])[0]]\n",
    "#     train_df = train_df[train_df.angle_from_station == le.transform(['self'])[0]]\n",
    "    \n",
    "    train_df = train_df.sort_values('time')\n",
    "    test_df = test_df.sort_values('time')    \n",
    "    \n",
    "    scale = StandardScaler()\n",
    "\n",
    "    test_df[df.columns] = scale.fit_transform(test_df[df.columns].as_matrix()).copy()\n",
    "    train_df[df.columns] = scale.fit_transform(train_df[df.columns].as_matrix()).copy()\n",
    "\n",
    "    X_train = train_df[train_columns]\n",
    "    Y_train = train_df[train_y_pollution]\n",
    "\n",
    "    X_test = test_df[train_columns]\n",
    "    Y_test = test_df[train_y_pollution]\n",
    "\n",
    "    print(\"For station : \" + station_name)\n",
    "    print(\"X columns : \" + str(list(X_test.columns)))\n",
    "    print(\"Y columns : \" + str(list(Y_test.columns))  )\n",
    "    print(\"Not Null: : \" + str(len(df)) + \" total: \" + str(len(df_air_quality)))\n",
    "\n",
    "    regr = MLPRegressor(hidden_layer_sizes=(20, ) , max_iter=1000, verbose=False, learning_rate_init=0.001)\n",
    "\n",
    "    print('Train/Test X \\t' + str(len(X_train)) +\"/\"+ str(len(X_test)))\n",
    "    print('Train/Test Y \\t ' + str(len(Y_train)) +\"/\"+ str(len(Y_test)))\n",
    "    print('Training neural Network model might take some time')\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    regr.fit( X_train , Y_train)\n",
    "    stop = timeit.default_timer()\n",
    "    train_time = int(stop - start)\n",
    "\n",
    "    pred_x = regr.predict(X_test)\n",
    "    print('Training finshed in ' + str(train_time) +  ' seconds')\n",
    "    print('Variance score: %.2f' % regr.score(X_test, Y_test))\n",
    "    print(\"Mean squared error for \")\n",
    "    print((np.mean((pred_x - Y_test) ** 2))) \n",
    "\n",
    "    joblib.dump(regr, 'classifier/spatial_'+station_name+'.pickle')\n",
    "\n",
    "    print(\"---\"*20)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    ct = 0 \n",
    "    \n",
    "    dict_ = {}\n",
    "    for item in Y_test.columns:\n",
    "\n",
    "        data = Y_test[item]\n",
    "        dict_[str(ct) + \"_pred\" ] = list(pred_x[:,ct])\n",
    "        dict_[str(ct) + \"_inp\" ]  =  data\n",
    "        ct+=1\n",
    "        \n",
    "    \n",
    "    return pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/grouped_weather_data_KT_A.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-8b35b8bdb2a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstations_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_regression_train_test_for_spatial_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-7e39dcad2143>\u001b[0m in \u001b[0;36mrun_regression_train_test_for_spatial_patterns\u001b[0;34m(station_name, test_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/grouped_weather_data_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstation_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, path, header, sep, index_col, parse_dates, encoding, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                           \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                           \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtupleize_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                           infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/grouped_weather_data_KT_A.csv' does not exist"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for station in stations_: \n",
    "    df = run_regression_train_test_for_spatial_patterns(station, 0.2)\n",
    "    results[station] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
